
# Задание
Проблема заказчика:
Компания планирует запустить новую платформу для обработки пользовательских запросов для вызова такси. Платформа должна быть масштабируемой, отказоустойчивой и соответствовать требованиям безопасности. Система должна выдерживать пиковую нагрузку в 50 000 запросов в секунду и обеспечивать согласованность данных.

# 1. Функциональные требования
* Заявка должна быть отправлена по нажатию на кнопку на фронте
* После отправки заявки кнопка должна быть заблокирована
* Возможность отправки двух разных заявок, дедупликация
* Заявки можно отправлять с web, mobile, api
* У заявки должен быть жизненный цикл и статусная модель
* У заявки есть исполнитель, заявитель, администратор
* Заявку можно редактировать после отправки, но только некоторые поля
* Заявка должна запускать бизнес процесс поиска исполнителя на бэкэнде
* Заявка должна иметь систему рейтинга
* Должна быть роль администратора, имеющего права изменять любую заявку
* Пользователь должен получать уведомления о смене статуса
* У пользователей должна быть возможность просмотра списка заявок, фильтрация, поиск
* *История изменений заявки должна сохраняться*


# 2. Нефункциональные требования
### Производительность
* в пике 50к заявок без просадки в производительности
* 99p rps 5к
* latency 99p 200ms
* latency high season 1000ms
* размеры заявки от 1KB до 5KB
* количество пользователей 1млн, кол-во таксистов 100к.
* *за минуту может быть обработано 100к заявок при средней нагрузке (throughput)*
### Отказоустойчивость
* система должна функционировать при отказе некритичных узлов
* при авариях должна быть graceful degradation
* RTO=1час RPO=5мин
* *для исключения лавинообразного падения части сервисов должен быть внедрён circuit breaker*
### Безопасность
* должна быть авторизация/аутентификация, OIDC
* пользователь может просматривать только свою заявку
* данные должны передаваться по защищенным протоколам, внутренние взаимодействия по mtls
* *Аудит. Кто и когда изменил заявку*
### Масштабируемость
* должен быть автоскейлинг в high season
* должна быть возможность горизонтального масштабироваться на регионы
* должна быть возможность горизонтального масштабироваться на органический рост
### Доступность
* система должна оставаться доступна при проблемах в сети или ее узлах, но при этом консистентность на первом месте
* SLA=99.99%
* *должны быть резервные каналы связи между ЦОД*
### Согласованность данных
* должна быть eventual consistency на уровне кластера
* max время несогласованности 3 мин
* *должна быть merge-логика при конфликтах версий при параллельных обновлениях*
* *strong consistency на уровне атомарных локальных вставок в БД*

# 3. Проект архитектуры

### Архитектурная схема
![Архитектура](https://github.com/serjteplov/system-design/blob/40eb2cba62596c1bf252b2e26e832a32d203279b/dz7%20-%20final%20project/arch.jpg)

### Деплоймент диаграмма
![Развертывание](https://github.com/serjteplov/system-design/blob/40eb2cba62596c1bf252b2e26e832a32d203279b/dz7%20-%20final%20project/dep.jpg)

### Предложенные решения
1. Сделать 3 кластера в разных географически распределенных регионах страны. Использование паттерна георезервирование дает плюсы к производительности и отказоустойчивости. Балансирока между ЦОДами делается на уровне Geo DNS.
2. На входе в каждый ЦОД стоит несколько балансировщиков, способных деражать высокую нагрузку. На балансировщиках настроены health чеки, таким образом если кластер не отвечает, балансировщик об этом быстро узнает и пользовательский запрос будет перенаправлен в другой ЦОД на уровне Geo DNS. Таким образом поддерживается отказоустойчивость на уровне ЦОДов.
3. Для раздачи статики фронта, а также кэширования медиа контента используется CDN
4. Запись тела заявки в БД происходит по событию из кафка. App-service отправляет событие в топик Кафки для сохранения заявок в БД, а также для запуска дальнейших процессов в стиле event driven. В частности запускается механизм поиска водителей и формирования заказа на поездку. 
5. Для обеспечения работы в high season, а также при пиковых нагрузках внедряется шардирование БД. В качестве ключа шардирования предлагается использовать userId+дата создания заявки. Данная стратегия позволит: равномерно распределить данные по всем шардам, хранить данные по одному пользователю в одном шарде и избегать кроссшардовых запросов, делать быструю выборку данных по дате за счет индекса. Использование данного паттерна позволяет миновать такие проблемы как множественные блокировки коллекций при записи, нагрузка на одну БД, долгие запросы на чтение, огромный индекс.
Но есть другой кейс: запрос и поиск заявок со стороны водителей. При ключе шардирования userId+createdAt это приведет к кроссшардовым запросам. Поэтому в качестве ключа шардирования можно рассмотреть regionId+userIdHash. Тут важно при шардировании по регионам не получить перегруженные шарды. Поэтому в ключ шардирования добавляем userIdHash и создаем побольше шардов для высокозагруженных регионов. Например для центрального региона будет 10 шардов, для Урала 3 шарда, для Дальнего востока 2 шарда.
6. Для обеспечения работы в high season, а также при пиковых нагрузках используется Kubernetes со встроенными механизмами service discovery, балансировки, автоскейлинга. При возрастании нагрузки, автоматически поднимаются новые поды чтобы держать нагрузку в high season. Также перед сохранением заявок в БД вводится буфер в виде топика Кафки, чтобы не перегружать шарды в моменты пиковой нагрузки.
Стартовый сайзинг: App-service - 3 пода, Search-service - 4 пода, Persist-service - 6 подов. Для топика заявок будет создано 48 партиций (16 х 3 брокера) с тем расчетом, что количество сервисов потребителей можно увеличить до 48. Таким образом, в пиковых нагрузках 50к rps, на каждый консюмер (инстанс сервиса) будет приходиться по ~1к rps. Это дает запас ресурсов на каждый сервис в период high season. Для топика запросов будет создано также 48 партиций. Система сама реактивно ищет водителю заказ и оповещает его, поэтому не ожидаем большого наплыва запросов на поиск заявок.
7. Для легкого горизонтального масштабирования бэкэнд сервисы разрабатываются по принципу stateless, что позволяет с легкостью добавлять или убирать инстансы по мере необходимости.
8. Перед входом в кластер установлен API Gateway, который служит местом применения кроссфункциональных паттернов, работающих на весь кластер (rate limiter, circuit breaker, authorization, logging)
9. Для решения проблемы актуальности и согласованности шардов на всех ЦОД, используется механизм CDC replication. Специальный сервис читает oplog mongoDB и все изменения отправляет в Кафку. Откуда потом изменения вычитываются и делается upsert в шард в других ЦОДах.
10. Для старых заявок организовано холодное хранение в архивном S3. Раз в сутки в сервисе-перекладчике запускается джоба, в результате которой устаревшие заявки попадают сначала в кафку, а затем в отдельно стоящий сервер хранилища S3. Данные хранятся в виде batch json. Аггрегация в S3 позволяет оценивать тренды на протяженни 3-5 лет, возможность поиска кто кого обслуживал. Для решения этой задачи можно сформировать политику тегов, которая позволит организовать хранение в S3 такое что данные позже можно будет найти.
11. Консенсус брокеров кафки, а также нод монги обеспечивается встроенными механизмами, позволяющими автоматически самостоятельно выбирать нового лидера.
12. Основная работа с заявками делается на ЦОД региона, при этом в другие ЦОДы не ходим. Данные реплицируются во все ЦОД на случай катасстрофы. При необходимости, в течении RTO=1ч работа будет восстановлена из нового места.
13. При проектировании системы мы намеренно отказались от кэша для отдачи заявок на фронт потому что в нем нет особого смысла. Дело в том что монга у нас шардированная, по ключу userId+дата, в каждом шарде есть индекс на userId и дату. Поэтому выборка заявки при read запросе из шарда будет очень быстрая. Но дело даже не в этом. В моей системе, пользователь будет оповещаться о статусе его заявки в реальном времени по SSE. Поэтому он не будет нагружать приложение частыми запросами на получение заявки. Таким образом, этих запросов будет мало, и они будут возникать в момент первоначального открытия приложения или перезагрузки приложения, когда будет отправляться первичный РЕСТ запрос на выгребание заявки из БД.
   Однако был добавлен кэш для быстрого получения Access token, это увеличит скорость проверки токенов.
14. Оценка размеров БД.

Возьмём 50к rps в пике. 50 000 * 5KB = 250MB/sec. Или 2Гбит/сек. Это будет максимальная пропускная способность всей системы при условии задачи 50к рпс в пике.

Возьмём медианную нагрузку в сутки 10к рпс. Кол-во секунд в сутках 86400.
86400 * 5KB * 10000 rps = 421 MB * 10000 =~ 4 TB. В разрабатываемой системе заявки хранятся за последние 3 дня, потом переносятся в архив. Таким образом на 3 дня потребуется 3*4=12 TB места суммарно на всех шардах монги. Архивные заявки будут храниться в S3, и через 1 год джоба хаускипинга удалит их навсегда. Объём данных в S3 = 4TB * 365 = 1460 TB

Скорость роста БД зависит от органического роста пользовательской базы и частоты совершения поездок. Если принять допущение, что каждые сутки становится +100 больше заказов. То за один день активная база (шарды монги) будет расти на 100*5KB = 500KB. Что равно ~14 МБ в месяц.

# 4. Выбор технологий
Ориентированность на бесплатные решения, т.к. разворачивается три ЦОД.
### GeoDNS с хэлс чеками у облачного правайдера
Используем данную технологию, чтобы в случае недоступности ЦОД перенаправлять пользователя на географически ближайший работающий ЦОД.
### Load Balancer - F5
Встроенный WAF, держит высокие нагрузки, хорошо зарекомендовал в энтерпрайзе, бесплатен.
### СУБД - MongoDB, Mongos
Простое в установке и сопровождении решение, бесплатное использование, огромное сообщество, есть локальный ACID, хорошие показатели при высоких нагрузках, встроенный механизм шардирования, стандарт документоориентированной БД. Есть удаление старых документов по TTL.
### Async messaging - Kafka
Стандарт в области обмена асинхронными сообщениями, ресурсоёмкая, но очень надежная и быстрая, из коробки даётся гарантия доставки at least once, возможность использовать Kafka Streams
### ЯП - Kotlin
Язык, на котором удобно создавать JVM приложения, сохранил всю мощь Java, добавлено удобство и синтаксический сахар, совместимость с jvm библиотеками и кодом.
### Контейнеризация, виртуализация - Kubernetes, Docker
Это стандарты, хорошо себя зарекомендовали, огромное сообщество, много документации, хорошо написанный и отлаженный за долгое время код.
### Auth Server - Keycloak
Стандарт в области безопасности, проверенное решение, бесплатное, можно писать плагины, возможность глубокой настройки.
### Для LDAP - FreeIPA
Есть multi-master репликация, совместим с Keycloak, широкие возможности настройки, open source.
### API Gateway - TYK
Широкие возможности настройки, можно писать плагины, хорошо держит высокие нагрузки, open source, хорошо зарекомендовал себя в энтерпрайзе.
### Хранилище S3 - minio 
Простая установка, проверенное отлаженное решение, поддерживается в Kubernetes, open source, есть синхронная репликация в distributed режиме
### Наблюдаемость
Стандарты энтерпрайза: Micrometer, Prometheus, Grafana, Fluent Bit, Elasticsearch, Greylog, Jaeger, OpenTelemetry
### Ingress controller - NGINX
Стандартный web-server.
### Front - React, Kotlin
Стандартные современные платформы для разработки FE решений.

# 5. Реализация нефункциональных требований

### Безопасность.
Используется классический OAuth2.0. В качестве authorization server используется Keycloak, пользователи и пароли хранятся в LDAP. Особенность - запись или изменение данных пользователя идет в LDAP-master, который расположен в главном ЦОД (Москва), в остальных ЦОДах LDAP работает в режиме read-only. Таким образом, вся рутина по получению и проверке токенов выполняется локально на каждом ЦОД, что положительно сказывается на производительности. Однако для изменения пароля, запрос будет перенаправлен в ЦОД-Москва.

Проверка access token осуществляется на API Gateway, который установлен перед Kubernetes кластером. Также, на API Gateway проводится авторизация входящего запроса к внутренним эндпоинтам.

Путь следования запроса из интернета выглядит следующим образом: запрос сначала попадает в публичный сегмент сети, где расположены 3 основые шлюза: Балансировщик, Firewall, API Gateway. Если запрос успешно авторизован, то он попадает в приватный сегмент сети “private-segment”. Между API Gateway и Kubernetes ingress controller установлено mTLS соединение для исключения попадания запросов в кластер в случае компрометации узлов публичного сегмента сети.

FreeIPA позволяет настроить механизм репликации multi-master из коробки, также из коробки предоставляется механизм failover и синхронизации. Однако для исключения коллизий одновременной мутации данных одного пользователя из разных ЦОДов, необходимо написать плагин в Keycloak, реализующий merge-логику по разрешению конфликта. При падении ЦОД с мастером LDAP, FreeIPA автоматически выберет нового мастера

### Наблюдаемость.
Основные компоненты наблюдаемости: логирование, трейсинг, метрики, визуализация, алёртинг.

* Для сбора, хранения и отображения логов используем связку Greylog, Fluent bit, Elasticsearch. В поде с приложением стоит fluent bit, который собирает логи и шлет их в Greylog через Kafka. Greylog сохраняет их в Elasticsearch и предоставляет UI с мощными инструментами поиска и фильтрации.
* Для работы трейсинга в сервисах стоит библиотека Jaeger. Она будет собирать трейсы и отсылать их в формате OpenTelemetry в collector, который сохраняет их в Elasticsearch. Визуализация трейсов происходит в отдельно развернутом инструменте Jaeger UI.
* Для сбора метрик используем pull модель. Каждое приложение будет отдавать метрики на определенном эндпоинте. Prometheus ходит по сервисам, собирает метрики и сохраняет в свою time series бд.
* Визуализация. Графана опрашивает прометеус по http, посылая promQL запросы в соотествии с метриками по которым установлен мониторинг. Визуализация данных проходит в UI графаны.
* Алёртинг. При достижении порогового значения по какой-либо метрике, графана отсылает эл.письмо, СМС, пуш-уведомление или сообщение в мессенджеры.

# 6. Риски и компромиссы

### Риск №1
Основное узкое место при записи заявок в БД. Пиковые нагрузки 50к рпс сильно влияют на производительность бэка и СУБД в худшую сторону. Поэтому было принято решение не записывать заявки сразу в монгу, а делать это через кафку, которая хорошо справляется и берет на себя всплески траффика.

### Риск №2
Авторизация запросов будет немного тормозить при возрастающей нагрузке. Добавление кэша для токенов решает эту проблему. Теперь есть кэш который во-первых снимает часть нагрузки с БД LDAP, во-вторых увеличивает скорость проверки токенов.

### Риск №2
Т.к. система состоит из 3 независимых ЦОД, то будут возникать накладки по времени актуализации и синхронизации данных между ЦОДами. Используется асинхронная репликация и eventual consistency, поэтому данные могут "обновляться" некоторое время. В период высокой нагрузки интервалы обновления могут увеличиваться

### Риск №3
Т.к. используется механизм шардирования, то кроссшардовые запросы для нужд приложения, администраторов, аналитиков, могут выполнятся долго.

### Риск №4
Т.к. для архивных данных используем холодное S3 хранилище с хранением данных в batch json, то время доступа к архитвным данным может составлять в худшем случае несколько минут.

### Риск №5
Т.к. на фронт сообщения попадают по SSE, то на бэке необходимо будет реализовывать логику переподключения при обрыве соединения.

### Риск №6
Риск решардинга при неправильном выборе ключа шардирования


