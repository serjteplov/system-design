
# Задание
Проблема заказчика:
Компания планирует запустить новую платформу для обработки пользовательских запросов для вызова такси. Платформа должна быть масштабируемой, отказоустойчивой и соответствовать требованиям безопасности. Система должна выдерживать пиковую нагрузку в 50 000 запросов в секунду и обеспечивать согласованность данных.

# 1. Функциональные требования
* Заявка должна быть отправлена по нажатию на кнопку
* После отправки заявки кнопка должна быть заблокирована
* Возможность отправки двух разных заявок, дедупликация
* Заявки можно отправлять с web, mobile, api
* У заявки должен быть жизненный цикл
* У заявки есть исполнитель, и заявитель
* Заявку можно редактировать после отправки, но только некоторые поля
* Заявка должна запускать бизнес процесс на бэкэнде
* Заявка должна иметь систему оценки
* Должна быть роль администратора, имеющего права изменять любую заявку
* *пользователь должен получать уведомления о смене статуса*
* *история изменений заявки должна сохраняться*
* *просмотр списка заявок, фильтрация, поиск*

# 2. Нефункциональные требования
### Производительность
* в пике 50к заявок без просадки в производительности
* 99p rps 5к
* latency 99p 200ms
* latency high season 1000ms
* *throughput за минуту может быть обработано 100к заявок при средней нагрузке*
### Отказоустойчивость
* система должна функционировать при отказе некритичных узлов
* при авариях должна быть graceful degradation
* RTO=1час RPO=5мин
* *Circuit breaker. Для исключения лавинообразного падения части сервисов применяем circuit breaker*
* *rate limiting*
* *fallback сценарии*
### Безопасность
* должна быть авторизация/аутентификация, OIDC
* пользователь может просматривать только свою заявку
* данные должны передаваться по защищенным протоколам, внутренние взаимодействия по mtls
* *Аудит. Кто и когда изменил заявку*
### Масштабируемость
* должен быть автоскейлинг в high season
* должна быть возможность горизонтального масштабироваться на регионы
* должна быть возможность горизонтального масштабироваться на органический рост
* *stateful stateless компоненты*
* *event driven архитектура*
### Доступность
* система должна оставаться доступна при проблемах в сети или ее узлах, но при этом консистентность на первом месте
* *SLA=99.99%*
* *резервные каналы связи между ЦОД*
### Согласованность данных
* должна быть eventual consistency
* max время несогласованности 3 мин
* *конфликт версий при параллельных обновлениях*
* *где нужна strong consistency*

# 3. Проект архитектуры

### Архитектурная схема
![Архитектура](https://github.com/serjteplov/system-design/blob/a065b27d0091f3f5187843cb881511b32014ea95/dz7%20-%20final%20project/arch.jpg)

### Деплоймент диаграмма
![Развертывание](https://github.com/serjteplov/system-design/blob/5e495cb6f1ee95aff7ac2c6b11e54f3ea0916b90/dz7%20-%20final%20project/dep.jpg)

### Предложенные решения
1. Сделать 3 кластера в разных географически распределенных регионах страны. Паттерн Георезервирование, геораспределенность. Дает плюсы к производительности и отказоустойчивости. Балансирока между ЦОДами делается на уровне Geo DNS.
2. На входе в каждый ЦОД стоит несколько балансировщиков, способных деражать высокую нагрузку. На балансировщиках настроены health чеки, таким образом если кластер не отвечает, балансировщик об этом быстро узнает и пользовательский запрос будет перенаправлен в другой ЦОД на уровне Geo DNS. Таким образом поддерживается отказоустойчивость на уровне ЦОДов.
3. Для раздачи статики фронта, а также кэширования медиа контента используется CDN
4. При записи тела заявки в БД, одновременно отправляется событие в топик Кафки для запуска дальнейших процессов в стиле event driven. В частности запускается механизм поиска водители и формирования заказа на поездку. Паттерн Transactional outbox.
5. Для обеспечения работы в high season, а также при пиковых нагрузках внедряется шардирование БД. Использование данного паттерна позволяет миновать такие проблемы как множественные блокировки коллекций при записи, вся нагрузка ляжет на одну БД, долгие запросы на чтение, огромный индекс.
6. Для обеспечения работы в high season, а также при пиковых нагрузках используется Kubernetes со встроенными механизмами service discovery, балансировки, автоскейлинга. При возрастании нагрузки, автоматически поднимаются новые поды чтобы держать нагрузку в high season (горизонтальное масштабирование).
7. Для легкого горизонтального масштабирования бэкэнд сервисы разрабатываются по принципу stateless, что позволяет с легкостью добавлять или убирать инстансы по мере необходимости.
8. Перед входом в кластер установлен API Gateway, который служит местом применения кроссфункциональных паттернов, работающих на весь кластер (rate limiter, circuit breaker, authorization, logging)
9. Для решения проблемы актуальности и согласованности шардов на всех ЦОД, используется механизм CDC replication. Специальный сервис читает oplog mongoDB и все изменения отправляет в Кафку. Откуда потом изменения вычитываются и делается upsert в шард в других ЦОДах.
10. Для старых заявок организовано холодное хранение в архивном S3. Раз в сутки в сервисе-перекладчике запускается джоба, в результате которой устаревшие заявки попадают сначала в кафку, а затем в отдельно стоящий сервер хранилища S3. Данные хранятся в виде batch json.
11. Консенсус брокеров кафки, а также нод монги обеспечивается встроенными механизмами, позволяющими автоматически самостоятельно выбирать нового лидера.

# 4. Выбор технологий

Geo DNS

Load Balancer - F5

Auth Server - Keycloak

LDAP - ???????????

WAF - ????????????

API Gateway - ??????????

S3 - minio

Наблюдаемость: Micrometer, Prometheus, Grafana, Fluent Bit, Elasticsearch, Greylog, Jaeger, OpenTelemetry

ЯП - Kotlin

Front - React, Kotlin

Front protocol - SSE

Виртуализация - Docker

Контейнеризация - Kubernetes

Ingress controller - NGINX

БД - MongoDB, Mongos

Async messaging - Kafka

# 5. Реализация нефункциональных требований

### Безопасность.
Используется классический OAuth2.0. В качестве authorization server используется Keycloak, пользователи и пароли хранятся в LDAP. Особенность - запись или изменение данных пользователя идет в LDAP-master, который расположен в главном ЦОД (Москва), в остальных ЦОДах LDAP работает в режиме read-only. Таким образом, вся рутина по получению и проверке токенов выполняется локально на каждом ЦОД, что положительно сказывается на производительности. Однако для изменения пароля, запрос будет перенаправлен в ЦОД-Москва.

Проверка access token осуществляется на API Gateway, который установлен перед Kubernetes кластером. Также, на API Gateway проводится авторизация входящего запроса к внутренним эндпоинтам.

Путь следования запроса из интернета выглядит следующим образом: запрос сначала попадает в публичный сегмент сети, где расположены 3 основые шлюза: Балансировщик, Firewall, API Gateway. Если запрос успешно авторизован, то он попадает в приватный сегмент сети “private-segment”. Между API Gateway и Kubernetes ingress controller установлено mTLS соединение для исключения попадания запросов в кластер в случае компрометации узлов публичного сегмента сети.

Вендор LDAP позволяет настроить механизм репликации master-slave из коробки. Однако для исключения коллизий одновременной мутации данных одного пользователя из разных ЦОДов, необходимо написать плагин в Keycloak, реализующий merge-логику по разрешению конфликта.

### Наблюдаемость.
Основные компоненты наблюдаемости: логирование, трейсинг, метрики, визуализация, алёртинг.

* Для сбора, хранения и отображения логов используем связку Greylog, Fluent bit, Elasticsearch. В поде с приложением стоит fluent bit, который собирает логи и шлет их в Greylog через Kafka. Greylog сохраняет их в Elasticsearch и предоставляет UI с мощными инструментами поиска и фильтрации.
* Для работы трейсинга в сервисах стоит библиотека Jaeger. Она будет собирать трейсы и отсылать их в формате OpenTelemetry в collector, который сохраняет их в Elasticsearch. Визуализация трейсов происходит в отдельно развернутом инструменте Jaeger UI.
* Для сбора метрик используем pull модель. Каждое приложение будет отдавать метрики на определенном эндпоинте. Prometheus ходит по сервисам, собирает метрики и сохраняет в свою time series бд.
* Визуализация. Графана опрашивает прометеус по http, посылая promQL запросы в соотествии с метриками по которым установлен мониторинг. Визуализация данных проходит в UI графаны.
* Алёртинг. При достижении порогового значения по какой-либо метрике, в графана отсылает эл.письмо, СМС, пуш-уведомление или сообщение в мессенджеры.

# 6. Риски и компромиссы

Риски - не хватит финансирования на установку и функционирование 3 ЦОД.
В случае если один из ЦОД не будет запущен, будет риск перегрузки одного из 2 оставшихся ЦОД, что может вылится к повышению конечного latency, а также к учащению аварий.
По условию задачи было определено что "система должна обеспечивать согласованность данных", поэтому при реализации проекта выбор будет сделан в пользу Консистентности, в то время как Доступность не может быть гарантирована.

Т.к. система состоит из 3 независимых ЦОД, то будут возникать накладки по времени актуализации и синхронизации данных между ЦОДами. Используется асинхронная репликация, поэтому данные могут "обновляться" некоторое короткое время.

Т.к. используются шарды, то кроссшардовые запросы, которые иногда могут возникать для нужд приложения или администраторов, будут выполнятся долго.

Т.к. для архивных данных используем холодное S3 хранилище, то время доступа к архитвным данным может составлять в худшем случае до минуты.

Т.к. на фронт сообщения попадают по SSE, то на бэке необходимо будет реализовывать логику переподключения при обрыве соединения.

Риск решардинга при неправильном выборе ключа шардирования


